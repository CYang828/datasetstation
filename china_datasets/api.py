from china_datasets.repo import DatasetRepo
from china_datasets.config import TMP_PATH, D_S
from china_datasets.util.s3 import s3_upload_files
from china_datasets.util.log import getLogger

from datasets import Dataset, load_dataset as hg_load_datasets
from yaspin import yaspin
from yaspin.spinners import Spinners


logger = getLogger()


def load_dataset(path, backend='s3', **kwargs):
    """
    Loads the dataset.
    """

    # è¯»å–æœ¬åœ°æ–‡ä»¶
    if path in ('csv', 'json', 'text', 'csv', 'parquet') and kwargs.get('data_files'):
        dataset = hg_load_datasets(path, **kwargs)
        return dataset
    else:
        repo = DatasetRepo()

        if not repo.is_exist(path):
            logger.warning('å½“å‰ä»“åº“ä¸å­˜åœ¨æ­¤æ•°æ®é›†ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ä¸Šä¼  <zhangchunyang_pri@126.com>')
            return None

        with yaspin(Spinners.moon, text="ä¸‹è½½ä¸­...") as spinner:
            try:
                dataset = repo.get(path)
                spinner.text = "ä¸‹è½½å®Œæˆ"
                spinner.ok("âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…")
                return dataset
            except BaseException as e:
                logger.error(e)
                spinner.text = "ä¸‹è½½å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ <zhangchunyang_pri@126.com>"
                spinner.fail("ğŸ™€ğŸ™€ğŸ™€ğŸ™€ğŸ™€ğŸ™€ğŸ™€ğŸ™€ğŸ™€ğŸ™€")
                return None 


def upload_dataset(dataset, name, **dataset_info):
    # éªŒè¯æ•°æ®é›†æ˜¯å¦åˆæ³•
    if not isinstance(dataset, Dataset):
        logger.error('å½“å‰ dataset å¯¹è±¡ä¸åˆæ³•ï¼Œç›®å‰æ”¯æŒ Huggingface Dataset å¯¹è±¡')
        return None

    repo = DatasetRepo()
    if repo.is_exist(name):
        logger.warning('å½“å‰ dataset åå­—å·²åœ¨ä»“åº“ä¸­å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ ')
        return None

    # å°†æ•°æ®é›†ä¿å­˜åˆ°æœ¬åœ°
    dataset_path = TMP_PATH.format(ds=name)
    dataset.save_to_disk(dataset_path)

    # ä¸Šä¼ æ•°æ®åˆ°è¿œç«¯
    s3_upload_files(name, dataset_path)
    return dataset
